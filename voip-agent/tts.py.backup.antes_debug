import os
import numpy as np
from piper import PiperVoice
from utils import resample_48k_to_8k, get_env, setup_log

class TTSWorker:
    def __init__(self):
        self.logger = setup_log(__name__)
        self.voice = '/root/.cache/piper/es_MX-claude-high.onnx'
        self.rate = float(get_env('PIPER_RATE', '1.0'))
        try:
            self.model = PiperVoice.load(self.voice)
            self.logger.info(f"Loaded Piper voice: {self.voice}")
        except Exception as e:
            self.logger.error(f"Failed to load Piper voice {self.voice}: {e}")
            raise

    def synthesize(self, text):
        """Synthesize text to audio using Piper TTS."""
        try:
            self.logger.info(f"Iniciando síntesis TTS para: {text[:50]}...")

            # Piper devuelve un generador de AudioChunk objects
            audio_generator = self.model.synthesize(text)

            # Recolectar chunks válidos y extraer audio
            audio_chunks = []
            total_samples = 0

            for i, chunk in enumerate(audio_generator):
                self.logger.info(f"Procesando chunk {i}: {type(chunk)}")

                # Extraer audio usando el atributo correcto descubierto
                audio_data = None

                try:
                    # SOLUCIÓN: Usar audio_int16_array que contiene el audio real
                    if hasattr(chunk, 'audio_int16_array'):
                        audio_data = chunk.audio_int16_array
                        self.logger.info(f"ÉXITO: Extraído {len(audio_data)} samples de audio_int16_array")
                    elif hasattr(chunk, 'audio_float_array'):
                        # Alternativa: usar audio_float_array y convertir
                        float_audio = chunk.audio_float_array
                        # CORRECCIÓN: Normalizar correctamente antes de convertir
                        float_audio = np.clip(float_audio, -1.0, 1.0)
                        audio_data = (float_audio * 32767).astype(np.int16)
                        self.logger.info(f"ÉXITO: Convertido {len(audio_data)} samples de audio_float_array")
                    else:
                        self.logger.error(f"Chunk {i} no tiene audio_int16_array ni audio_float_array")
                        continue

                    # CORRECCIÓN: Verificar y normalizar el audio int16
                    if isinstance(audio_data, np.ndarray) and audio_data.size > 0:
                        # Verificar si hay clipping o valores extremos
                        if audio_data.dtype == np.int16:
                            # Verificar estadísticas para detectar problemas
                            min_val, max_val = audio_data.min(), audio_data.max()
                            if min_val < -32768 or max_val > 32767:
                                self.logger.warning(f"Chunk {i} tiene valores fuera de rango: min={min_val}, max={max_val}")
                                audio_data = np.clip(audio_data, -32768, 32767).astype(np.int16)
                            
                            # Detectar posible saturación (demasiados valores máximos)
                            saturated_samples = np.sum(np.abs(audio_data) >= 32700)
                            if saturated_samples > len(audio_data) * 0.1:  # Más del 10% saturado
                                self.logger.warning(f"Chunk {i} posiblemente saturado: {saturated_samples}/{len(audio_data)} samples")
                                # Reducir ganancia para evitar distorsión
                                audio_data = (audio_data * 0.8).astype(np.int16)
                        
                        audio_chunks.append(audio_data)
                        total_samples += len(audio_data)
                        self.logger.info(f"Chunk {i} agregado: {len(audio_data)} samples (rango: {audio_data.min()} a {audio_data.max()})")
                    else:
                        self.logger.error(f"Chunk {i} audio inválido: {type(audio_data)}")

                except Exception as chunk_error:
                    self.logger.error(f"Error extrayendo chunk {i}: {chunk_error}")

            self.logger.info(f"=== RESUMEN EXTRACCIÓN ===")
            self.logger.info(f"Chunks procesados: {len(audio_chunks)}")
            self.logger.info(f"Total samples: {total_samples}")

            if not audio_chunks:
                self.logger.error("No se extrajo audio válido")
                return self._generate_fallback_tone()

            # CORRECCIÓN: Concatenar chunks con verificación de tipos
            if len(audio_chunks) == 1:
                audio = audio_chunks[0]
            else:
                try:
                    # Asegurar que todos los chunks tengan el mismo dtype
                    audio_chunks = [chunk.astype(np.int16) for chunk in audio_chunks]
                    audio = np.concatenate(audio_chunks)
                    self.logger.info(f"Audio concatenado: {len(audio)} samples")
                except ValueError as concat_error:
                    self.logger.error(f"Error concatenando: {concat_error}")
                    audio = audio_chunks[0]

            # Verificar resultado final
            self.logger.info(f"Audio final: {len(audio)} samples, dtype: {audio.dtype}")

            if len(audio) == 0:
                return self._generate_fallback_tone()

            # CORRECCIÓN: Procesamiento final del audio
            if audio.dtype == np.int16:
                audio_final = audio
            else:
                # Convertir a int16 si es necesario
                if audio.dtype in [np.float32, np.float64]:
                    audio = np.clip(audio, -1.0, 1.0)
                    audio_final = (audio * 32767).astype(np.int16)
                else:
                    audio_final = audio.astype(np.int16)

            # CORRECCIÓN ADICIONAL: Aplicar fade-in y fade-out para evitar clicks
            fade_samples = min(220, len(audio_final) // 10)  # 10ms fade a 22kHz
            if len(audio_final) > fade_samples * 2:
                # Fade-in
                fade_in = np.linspace(0, 1, fade_samples)
                audio_final[:fade_samples] = (audio_final[:fade_samples] * fade_in).astype(np.int16)
                
                # Fade-out
                fade_out = np.linspace(1, 0, fade_samples)
                audio_final[-fade_samples:] = (audio_final[-fade_samples:] * fade_out).astype(np.int16)

            # DEBUG: Guardar audio como WAV para diagnóstico
            try:
                import scipy.io.wavfile as wavfile
                debug_wav_path = f"/tmp/debug_tts_{len(audio_final)}.wav"
                wavfile.write(debug_wav_path, 22050, audio_final)
                self.logger.info(f"DEBUG: Audio guardado como {debug_wav_path}")
                
                # Verificar estadísticas del audio final
                audio_stats = {
                    'samples': len(audio_final),
                    'min': int(audio_final.min()),
                    'max': int(audio_final.max()),
                    'mean': float(audio_final.mean()),
                    'std': float(audio_final.std()),
                    'saturated': int(np.sum(np.abs(audio_final) >= 32700))
                }
                self.logger.info(f"DEBUG: Audio stats - {audio_stats}")
                
            except Exception as debug_error:
                self.logger.info(f"DEBUG: Error guardando WAV: {debug_error}")

            # CORRECCIÓN CRÍTICA: Eliminar resample destructivo
            self.logger.info(f"Audio final listo a 22050Hz: {len(audio_final)} samples (sin resample destructivo)")
            return 22050, audio_final

        except Exception as e:
            self.logger.error(f"TTS synthesis failed: {e}")
            import traceback
            self.logger.error(f"Traceback: {traceback.format_exc()}")
            return self._generate_fallback_tone()

    def _generate_fallback_tone(self):
        """Generar un tono simple como fallback cuando TTS falla."""
        try:
            # CORRECCIÓN: Mejorar el tono fallback para que sea más suave
            duration = 1.0
            sample_rate = 22050
            t = np.linspace(0, duration, int(sample_rate * duration), False)
            
            # Crear un tono más agradable con múltiples frecuencias
            frequency1 = 440  # La nota A
            frequency2 = 523  # Do
            audio_fallback = (np.sin(2 * np.pi * frequency1 * t) * 0.15 + 
                            np.sin(2 * np.pi * frequency2 * t) * 0.10)
            
            # Aplicar fade-in y fade-out suave
            fade_samples = int(sample_rate * 0.05)  # 50ms fade
            fade_in = np.linspace(0, 1, fade_samples)
            fade_out = np.linspace(1, 0, fade_samples)
            
            audio_fallback[:fade_samples] *= fade_in
            audio_fallback[-fade_samples:] *= fade_out
            
            audio_fallback_int16 = (audio_fallback * 32767).astype(np.int16)

            self.logger.info("Generado audio fallback: tono armónico a 22kHz con fades")
            return sample_rate, audio_fallback_int16

        except Exception as fallback_error:
            self.logger.error(f"Error generando fallback: {fallback_error}")
            return 22050, np.array([], dtype=np.int16)
