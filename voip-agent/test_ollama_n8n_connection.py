#!/usr/bin/env python3
import requests
import json
import time

def test_ollama_connection():
    """Probar la conexiÃ³n directa a Ollama"""
    print("ğŸ§ª Testing Ollama Docker connection...")

    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=10)
        if response.status_code == 200:
            models = response.json()
            print(f"âœ… Ollama is running with {len(models['models'])} models")
            for model in models['models']:
                print(f"   - {model['name']}")
            return True
        else:
            print(f"âŒ Ollama returned status: {response.status_code}")
            return False
    except Exception as e:
        print(f"âŒ Failed to connect to Ollama: {e}")
        return False

def test_ollama_generation():
    """Probar generaciÃ³n de texto con Ollama"""
    print("\nğŸ¤– Testing Ollama text generation...")

    payload = {
        "model": "llama3.2:3b-instruct-q4_k_m",
        "prompt": "Hola, Â¿cÃ³mo estÃ¡s? Responde brevemente en espaÃ±ol.",
        "stream": False
    }

    try:
        response = requests.post("http://localhost:11434/api/generate",
                               json=payload, timeout=30)
        if response.status_code == 200:
            result = response.json()
            print(f"âœ… Generation successful:")
            print(f"   Prompt: {payload['prompt']}")
            print(f"   Response: {result['response']}")
            return True
        else:
            print(f"âŒ Generation failed with status: {response.status_code}")
            return False
    except Exception as e:
        print(f"âŒ Failed to generate text: {e}")
        return False

def test_n8n_access():
    """Verificar acceso a n8n"""
    print("\nğŸŒ Testing n8n access...")

    try:
        response = requests.get("http://localhost:5678", timeout=10)
        if response.status_code == 200:
            print("âœ… n8n is accessible at http://localhost:5678")
            print("   Username: admin")
            print("   Password: Sparkurlife5.")
            return True
        else:
            print(f"âŒ n8n returned status: {response.status_code}")
            return False
    except Exception as e:
        print(f"âŒ Failed to access n8n: {e}")
        return False

def show_docker_status():
    """Mostrar estado de contenedores Docker"""
    print("\nğŸ³ Docker Container Status:")
    import subprocess
    try:
        result = subprocess.run(["docker", "ps", "--format",
                               "table {{.Names}}\t{{.Image}}\t{{.Status}}\t{{.Ports}}"],
                               capture_output=True, text=True, check=True)
        print(result.stdout)
    except Exception as e:
        print(f"âŒ Failed to get Docker status: {e}")

def main():
    print("=" * 60)
    print("ğŸš€ OLLAMA + N8N DOCKER CONNECTION TEST")
    print("=" * 60)

    show_docker_status()

    # Probar cada componente
    ollama_ok = test_ollama_connection()
    n8n_ok = test_n8n_access()

    if ollama_ok:
        generation_ok = test_ollama_generation()
    else:
        generation_ok = False

    print("\n" + "=" * 60)
    print("ğŸ“Š SUMMARY")
    print("=" * 60)
    print(f"Ollama Docker:     {'âœ… OK' if ollama_ok else 'âŒ FAIL'}")
    print(f"Text Generation:   {'âœ… OK' if generation_ok else 'âŒ FAIL'}")
    print(f"n8n Access:        {'âœ… OK' if n8n_ok else 'âŒ FAIL'}")

    if ollama_ok and n8n_ok:
        print("\nğŸ‰ SUCCESS! Your configuration is working correctly!")
        print("\nğŸ“‹ Next Steps:")
        print("1. Go to http://localhost:5678")
        print("2. Login with admin / Sparkurlife5.")
        print("3. Your Ollama credentials should now use: http://ollama:11434")
        print("4. Test your workflow - the connection should work!")
        print("\nğŸ’¡ The containers can communicate using the service name 'ollama'")
    else:
        print("\nâŒ Some components are not working properly.")
        print("Please check the Docker containers and network configuration.")

if __name__ == "__main__":
    main()